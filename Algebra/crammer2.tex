
\magnification=1200
\def\p{\partial}
\def\t {\tilde}
\def \m {\medskip}
\def\degree {{\bf {\rm degree}\,\,}}
\def \finish {${\,\,\vrule height1mm depth2mm width 8pt}$}





\def\a {\alpha}
\def\vare{{\varepsilon}}
\def\l {\lambda}
\def\s {{\sigma}}

\def\G {{\Gamma}}

\def\A {{\bf A}}
\def\C {{\bf C}}
\def\E  {{\bf E}}
\def\K {{\bf K}}
\def\N {{\bf N}}
\def\Q {{\bf Q}}
\def\R  {{\bf R}}
\def\V {{\cal V}}
\def \X   {{\bf X}}
\def \Y   {{\bf Y}}
\def\Z {{\bf Z}}


\def\c {{\bf c}}
\def\ac {{\bf a}}
\def\e{{\bf e}}
\def\f {{\bf f}}
\def\n {{\bf n}}
\def\r {{\bf r}}
\def\v {{\bf v}}
\def \x   {{\bf x}}
\def \y   {{\bf y}}
\def\o {\omega}

\def\pt {{\bf pt}}



\centerline {\bf Geometrical meaning of Crammer rule.}

\bigskip

{\it The Crammer rule which you can find in any handbooks for mathematical calcualtions for engineers
may be seems to be little bit annoying for mathematicians. But it has a very simple and beautiful geometrical meaning}

\medskip

  We know Crammer rule. It states the following:

   Consider $n$ simultaneous linear equations for $n$ unknowns:
                 $$
                A\x={\bf c}\,,
                \eqno (0.1)
                 $$
where $A$ is $n\times n$ matrix, $\bf c$ is $n\times 1$  matrix with real entries ,
$\x$ is $n\times 1$ of unknowns.
 (We can view $\x,\c$ as vectors $\x=x^i\e_i$ in $\R ^n$ and $A$ as a linear operator).

The solution of this system, the vector $\x=A^{-1}\c$ can be calculated in many different ways.
The following receipt of  calculations is practical:

If we remove $i$-th row from the matrix $A$ and put instead it the vector $\c$ we come to the matrix
which we denote by $A_i$:
      If matrix $A$ can be considered as the ordered set of $n$ vectors:
          $$
       A=(\ac_1,\dots,\ac_n)
       \eqno (0.2)
          $$
then
           $$
     A_1=(\c,\ac_2,\dots,\ac_n)\,,A_2=(\ac_1,\c,\ac_3,\dots,\ac_n)\,,
     A_{n-1}=(\ac_1,\dots,\ac_{n-2},\c,\ac_n)\,\,,A_{n}=(\ac_1,\dots,\ac_{n-1},\c)
           $$
{\it Crammer} rule tells that in the case if $\det A\not=0$ then the solution of the system (0.1) is
           $$
        x^i={\det A_i\over \det A}\,,   (i=1,2,\dots,n)
        \eqno (0.3)
           $$
This rule is may be the best known formula in Linear Algebra for the wide community of non-mathematicians.
(For example you can find it in any mathematical manual for engineers.)

There are million proofs of this elementary formula. I would like to expose here just one
which looks nice (and which can be generalised for graded spaces).
\m

\centerline {\bf Crammer identity and Crammer rule}
\m



  We use exterior $n$-form on $\R^n$. Exterior $n$-form $\o(\x_1,\dots,\x_n)$
is bilinear $n$-form (function on $n$ vectors which is linear with respect to all vectors)
 and which is {\it antysymmetrical} with  respect to any two vectors:
               $$
       \o(\ldots,\x_i,\ldots, \x_j,\ldots)=-\o(\ldots,\x_j,\ldots, \x_i,\ldots)\,.
                   \eqno (0.4)
               $$
In particular this means that for any vector $\x$
               $$
\o(\ldots,\x,\ldots, \x,\ldots)=0\,.
\eqno (0,4a)
                $$
(In fact conditions (0.4) and (0,4a) for bilinear forms are equivalent: show it.)

An example of exterior $n$-form is  determinant: Choose a  basis and consider
             $$
        \o(\x_1,\x_2,\dots,\x_n)=\det (\x_1,\dots,\x_n)\,,
\eqno (0.5)
             $$
where  $(\x_1,\dots,\x_n)$ in the right hand side
is $n\times n$ matrix composed of vectors $\x_1,\dots,\x_n$ in the chosen basis.

{\bf Exercise}  Any exterior form is proportional to (0.5).

\m

  {\bf Exterior $n$-form in $\R^n$ defines the volume of $n$-parallelepiped:
    $\o(\x_1,\dots,\x_n)$ can be considered as a volume of parallelepiped formed by vectors
      $\x_1,\dots,\x_n$.}


      \bigskip


{\bf Proposition}

{\it Let $\o$ be an arbitrary exterior  $n$-form on $\R^n$ and vector $\c$ belongs to the span of the vectors
$\{\ac_1,\dots,\ac_n\}$, i.e.
                            $$
                      \c=c^k\ac_k=c^1\ac_1+c^2\ac_2+\dots+c^n\ac_n
                            $$



Then the following identity takes place
               $$
\o(\ac_1,\ac_2,\dots,\ac_n)\c=
      $$
      $$
      \o(\c,\ac_2,\ac_3,\dots,\ac_n)\ac_1+\o(\ac_1,\c,\ac_3,\dots,\ac_n)\ac_2+
\dots +\o(\ac_1,\ac_2,\ac_3,\dots,\ac_{n-1},\c)\ac_n\
\eqno (1.1)
               $$
 }
\m
We call this identity {\sl Crammer} identity

\m

{\bf Remark}
Here and everywhere $c^k$ is $k$-th component of the vector $\c$, not the $k$-th power of the $c$!!!)

\m

Crammer rule immediately follows from the Crammer identity. Indeed let $\o$
be a non-degenerate exterior $n$ form.
Then the equation (0.1) means that
        $$
\c=x^i\ac_i=c^1\ac_1+c^2\ac_2+\dots+c^n\ac_n\,,
\eqno (1.2)
        $$
        where $\ac_i$ are rows of the matrix $A$ (see (0.2)).
On the other hand due to Crammer identity  (1.1)
              $$
 \c={\o(\c,\ac_2,\ac_3,\dots,\ac_n)\over \o(\ac_1,\ac_2,\dots,\ac_n)}\ac_1+
    {\o(\ac_1,\c,\ac_3,\dots,\ac_n)\over \o(\ac_1,\ac_2,\dots,\ac_n)}\ac_2+
\dots +
    {\o(\ac_1,\ac_2,\ac_3,\dots,\ac_{n-1},\c)\over \o(\ac_1,\ac_2,\dots,\ac_n)}\ac_n=
              $$
               $$
c^1{\det(\c,\ac_2,\ac_3,\dots,\ac_n)\over \det(\ac_1,\ac_2,\dots,\ac_n)}+
c^2{\det(\ac_1,\c,\ac_3,\dots,\ac_n)\over \det(\ac_1,\ac_2,\dots,\ac_n)}+
\dots c^n{\det(\ac_1,\ac_2,\ac_3,\dots,\ac_{n-1},\c)\over \det(\ac_1,\ac_2,\dots,\ac_n)}
\eqno (1.3)
               $$
   Comparing (1.2)and (1.3) we come to (0.3).

   \m

   It remains to prove Crammer identity (1.1):


\m

{\sl Proof of Crammer identity.}

   It is just one enough long line:  Let
   $c=c^1\ac_1+c^2\ac_2+\dots+c^n\ac_n$. Then using linearity and anitsymmetricity (0.4), (0.4a) we come to
              $$
\o(\ac_1,\ac_2,\dots,\ac_n)\c=\o(\ac_1,\ac_2,\dots,\ac_n)\left(c^1\ac_1+c^2\ac_2+\dots+c^n\ac_n\right)=
               $$
         $$
 c_1\o(\ac_1,\ac_2,\dots,\ac_n)\ac_1+
 c_2\o(\ac_1,\ac_2,\dots,\ac_n)\ac_2+\dots+
 c_n\o(\ac_1,\ac_2,\dots,\ac_n)\ac_n=
          $$
         $$
\o(c_1\ac_1,\ac_2,\dots,\ac_n)\ac_1+
 \o(\ac_1,c_2\ac_2,\dots,\ac_n)\ac_2+\dots+
 \o(\ac_1,\ac_2,\dots,c_n\ac_n)\ac_n=
           $$
           $$
\o(c_1\ac_1+c_2\ac_2+\dots+c_n\ac_n,\ac_2,\dots,\ac_n)\ac_1+
\o(\ac_1,c_1\ac_1+c_2\ac_2+\dots+c_n\ac_n,\dots,\ac_n)\ac_2+\dots+
 \dots=
           $$
           $$
\o(\c,\ac_2,\dots,\ac_n)\ac_1+
 \o(\ac_1,\c,\dots,\ac_n)\ac_2+\dots+
 \o(\ac_1,\ac_2,\dots,\ac_{n-1},\c)\ac_n.
           $$
It is worth to note that these considerations can be generalised for linear operators on $Z_2$-spaces (superspaces)
(Here very interesting mathematics begins (see the works on Berezinians of T. Voronov and mine. ))

\m


   All the best

        H.M.K. 12.01.10

\m



\bye
